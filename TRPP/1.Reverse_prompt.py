import csv
import time
from openai import OpenAI

client = OpenAI(
    base_url='https://xiaoai.plus/v1',
    api_key='sk-XXX'  # 替换为你的 API Key
)

# 参数配置
input_file = 'FuExp/Dataset/wiki_csai.csv'  # 输入CSV文件路径
output_file = 'FuExp/newMethod/wiki_csai_prompt_pre.csv'  # 输出CSV文件路径
start_row = 0  # 起始行号
end_row = 2  # 结束行号
row_step = 3  # 行步长
sleep_time = 20  # 每次请求之间的间隔时间（秒）

# prompt 模板：用于生成3个可能的 prompts
prompt_template = (
    "Based on the following text, generate 3 possible prompts that might have generated it:\n"
    "Text: "
)


# # prompt 模板
# prompt_template = (
#     "What prompts were used when generating this text using LLM? Please list the three most likely prompts.\n"
#     "Text: "
# )

# prompt_template = (
#     "Provide the three most likely prompts that were used when generating this text using an LLM.\n"
#     "Text: "
# )

def read_csv_row_range(csv_file, start_row, end_row):
    """读取指定范围内的CSV行"""
    with open(csv_file, 'r', encoding='utf-8', errors='ignore') as file:
        csv_reader = csv.reader(file)
        for index, row in enumerate(csv_reader):
            if start_row <= index + 1 <= end_row:
                yield row

def generate_prompts(text):
    """生成 3 个可能的 prompt"""
    messages = [{"role": "user", "content": f"{prompt_template}{text}"}]
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages
    )
    prompts = completion.choices[0].message.content.split('\n')
    return [p.strip() for p in prompts if p]

def generate_text_from_prompts(prompts):
    """用每个 prompt 生成对应的文本"""
    responses = []
    for prompt in prompts:
        message = [
            {"role": "user", "content": prompt}
        ]
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=message
        )
        response = completion.choices[0].message.content.strip()
        responses.append(response)
    return responses

def select_most_likely_prompt(text, prompts, responses):
    """选择最可能的 prompt"""
    messages = [
        {
            "role": "user",
            "content": (
                   f"The following text:\n\n'{text}'\n\n"
                   f"was most likely generated by one of the following prompts. Below are the prompts and the corresponding responses:\n\n"
                   f"1. Prompt: {prompts[0]}\n   Generated Response: {responses[0]}\n\n"
                   f"2. Prompt: {prompts[1]}\n   Generated Response: {responses[1]}\n\n"
                   f"3. Prompt: {prompts[2]}\n   Generated Response: {responses[2]}\n\n"
                   "Based on this information, select the prompt that most likely generated the text. Respond with the number 1, 2, or 3."
    )
    }
    ]
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages
    )
    selected_number = completion.choices[0].message.content.strip()

    # 提取数字，确保返回的结果有效
    import re
    match = re.search(r'\b[1-3]\b', selected_number)
    if match:
        return prompts[int(match.group(0)) - 1]
    else:
        raise ValueError(f"Unexpected response format: {selected_number}")

# 主流程
with open(input_file, 'r', encoding='utf-8', errors='ignore') as file:
    total_lines = sum(1 for _ in file)

while start_row < total_lines:
    if end_row > total_lines:
        end_row = total_lines

    for row in read_csv_row_range(input_file, start_row, end_row):
        original_text = row[1]
        label = row[0]
        print(f"Processing text: {original_text}")

        # Step 1: 生成 3 个可能的 prompt
        prompts = generate_prompts(original_text)
        print(f"Generated Prompts: {prompts}")

        # Step 2: 用每个 prompt 生成对应的文本
        generated_responses = generate_text_from_prompts(prompts)
        print(f"Generated Responses: {generated_responses}")

        # Step 3: 根据 prompt 和生成的文本选择最可能的一个
        most_likely_prompt = select_most_likely_prompt(original_text, prompts, generated_responses)
        formatted_prompt = f"The prompt used for generating this text could be: {most_likely_prompt}"

        # 保存结果到 CSV 文件
        with open(output_file, 'a', encoding='utf-8', newline='') as file:
            writer = csv.writer(file)
            writer.writerow([label, original_text, formatted_prompt])

        time.sleep(sleep_time)  # 避免频繁请求导致 API 限流

    # 更新行号范围
    start_row += row_step
    end_row += row_step

print(f"所有结果已成功保存到 {output_file} 文件中。")
